{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from skimage.util import random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(DEVICE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Define a demo neural network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # If using a Linear network\n",
    "        # self.flatten = nn.Flatten()\n",
    "        # self.linear_relu_stack = nn.Sequential(\n",
    "        #     nn.Linear(28 * 28, 512),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(512, 512),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(512, 10)\n",
    "        # )\n",
    "\n",
    "        # If using a CNN\n",
    "        self.conv_relu_stack = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Dropout2d(p=0.5),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Dropout2d(p=0.5)\n",
    "        )\n",
    "        self.linear = nn.Linear(7 * 7 * 64, 10, bias=True)\n",
    "\n",
    "    def forward(self, sample):\n",
    "        \"\"\"\n",
    "        Computes the outputs of the network from the input sample\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sample : tensor\n",
    "            The input sample\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : tensor\n",
    "            The output of the network\n",
    "        \"\"\"\n",
    "        # For a Linear network\n",
    "        # sample = self.flatten(sample)\n",
    "        # out = self.linear_relu_stack(sample)\n",
    "\n",
    "        # For a CNN\n",
    "        out = self.conv_relu_stack(sample)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SaltPepperTransform:\n",
    "    \"\"\"\n",
    "    Define a custom PyTorch transform to implement \n",
    "    Salt and Pepper Data Augmentation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, amount):\n",
    "        \"\"\"\n",
    "        Pass custom parameters to the transform in init\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        amount : float\n",
    "            The amount of salt and pepper noise to add to the image sample\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.amount = amount\n",
    "\n",
    "        # conversion transforms we will use\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.to_pil = transforms.ToPILImage()\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        Transform the sample when called\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sample : PIL.Image\n",
    "            The image to augment with noise\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        noise_img : PIL.Image\n",
    "            The image with noise added\n",
    "        \"\"\"\n",
    "        salt_img = torch.tensor(random_noise(self.to_tensor(sample),\n",
    "                                             mode='salt', amount=self.amount))\n",
    "\n",
    "        return self.to_pil(salt_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_dataloaders():\n",
    "    \"\"\"\n",
    "    Gets the DataLoaders that will be used in the demo\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_dataloader : torch.utils.data.DataLoader\n",
    "        The DataLoader containing the training data\n",
    "    test_dataloader : torch.utils.data.DataLoader\n",
    "        The DataLoader containing the test data\n",
    "    \"\"\"\n",
    "\n",
    "    # Download training data from open datasets.\n",
    "    training_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        # transform=ToTensor(),\n",
    "        transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomRotation(90),\n",
    "            transforms.RandomAffine(90, (0.3, 0.3), (1.0, 2.0)),\n",
    "            SaltPepperTransform(0.05),\n",
    "            transforms.ToTensor()\n",
    "        ]),\n",
    "    )\n",
    "\n",
    "    # Download test data from open datasets.\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "    test_data = test_dataloader.dataset[0]\n",
    "    test_sample = test_data[0]\n",
    "    test_score = test_data[1]\n",
    "    print('Shape of Test Samples: [N, C, H, W]: {}'.format(test_sample.shape))\n",
    "    print('Test Score y: {} type: {}'.format(test_score, type(test_score)))\n",
    "\n",
    "    return train_dataloader, test_dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_network(dataloader, training_model, loss_function):\n",
    "    \"\"\"\n",
    "    Trains the demo network\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataloader : torch.utils.data.DataLoader\n",
    "        The DataLoader with the training data\n",
    "    training_model : nn.Module\n",
    "        The network being trained\n",
    "    loss_function : CrossEntropyLoss\n",
    "        The loss function used in training\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Define the optimizer that will train the network model\n",
    "    optimizer = torch.optim.SGD(training_model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Set the network in training mode that enables some training-only \n",
    "    # layers like dropout\n",
    "    training_model.train()\n",
    "\n",
    "    # Perform the training\n",
    "    total_training_size = len(dataloader.dataset)\n",
    "    for batch, (sample, score) in enumerate(dataloader):\n",
    "\n",
    "        # Copy the sample to the device doing the calculations\n",
    "        sample, score = sample.to(DEVICE), score.to(DEVICE)\n",
    "\n",
    "        # Compute prediction error between the model output and the \n",
    "        # training score\n",
    "        prediction = training_model(sample)\n",
    "        loss = loss_function(prediction, score)\n",
    "\n",
    "        # Perform backpropagation and update the network weights to minimize \n",
    "        # the error\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Output the score every 100th training iteration so output \n",
    "        # window is not spammed\n",
    "        if batch % 100 == 0:\n",
    "            loss, current_batch = loss.item(), batch * len(sample)\n",
    "            print('Current Loss: {} Training Progress: [{} / {}]'.format(\n",
    "                loss, current_batch, total_training_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_network(dataloader, test_model, loss_function):\n",
    "    \"\"\"\n",
    "    Runs the demo network in validation mode\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataloader : torch.utils.data.DataLoader\n",
    "        The DataLoader with the validation testing data\n",
    "    test_model : nn.Module\n",
    "        The network being validated\n",
    "    loss_function : CrossEntropyLoss\n",
    "        The loss function used in validation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Set the network into evaluation mode\n",
    "    test_model.eval()\n",
    "\n",
    "    # Initializes the counts to zero\n",
    "    num_correct = 0.0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Disable the gradient calculation since not training\n",
    "    with torch.no_grad():\n",
    "        for sample, score in dataloader:\n",
    "\n",
    "            # Copy the sample to the device doing the calculations\n",
    "            sample, score = sample.to(DEVICE), score.to(DEVICE)\n",
    "\n",
    "            # Compute prediction error between the model output and the \n",
    "            # training score\n",
    "            prediction = test_model(sample)\n",
    "            total_loss = loss_function(prediction, score).item()\n",
    "\n",
    "            num_correct += (prediction.argmax(1) == score).type(\n",
    "                               torch.float).sum().item()\n",
    "\n",
    "    # Calculate the average loss by dividing by the number of batches\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "\n",
    "    # Calculate the fraction of correct outputs\n",
    "    percent_correct = 100.0 * (num_correct / len(dataloader.dataset))\n",
    "    print('Accuracy: {}%, Average Loss: {}'.format(\n",
    "        percent_correct, average_loss))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Set the training batch size and number of training epochs\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 5\n",
    "\n",
    "    # Get the network model\n",
    "    model = NeuralNetwork().to(DEVICE)\n",
    "    print(model)\n",
    "\n",
    "    # Define the loss function to use and\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Get the training and testing data. If the data does not exist on \n",
    "    # the local disk, it will download and save it. Local copy will \n",
    "    # be used on future runs\n",
    "    train_dl, test_dl = get_dataloaders()\n",
    "\n",
    "    for i in range(EPOCHS):\n",
    "        print('Training Epoch: {}'.format(i + 1))\n",
    "        print('---------------------')\n",
    "        train_network(train_dl, model, loss_func)\n",
    "        test_network(test_dl, model, loss_func)\n",
    "    print('Complete')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
